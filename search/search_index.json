{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".md-typeset h1, .md-content__button { display: none; } This is a modern Cookiecutter template that can be used to initiate a Python project with all the necessary tools for development, testing, and deployment. It supports the following features: Poetry for dependency management CI/CD with GitHub Actions Pre-commit hooks with pre-commit Code quality with ruff , mypy , deptry and prettier Publishing to Pypi or Artifactory by creating a new release on GitHub Testing and coverage with pytest and codecov Documentation with MkDocs Compatibility testing for multiple versions of Python with Tox Containerization with Docker Development environment with VSCode devcontainers An example of a repository generated with this package can be found here . Quickstart \u00b6 On your local machine, navigate to the directory in which you want to create a project directory, and run the following two commands: pip install cookiecutter-poetry ccp Alternatively, install cookiecutter and directly pass the URL to this Github repository to the cookiecutter command: pip install cookiecutter cookiecutter https://github.com/fpgmaas/cookiecutter-poetry.git Create a repository on GitHub, and then run the following commands, replacing <project-name> , with the name that you gave the Github repository and <github_author_handle> with your Github username. cd <project_name> git init -b main git add . git commit -m \"Init commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main Finally, install the environment and the pre-commit hooks with make install You are now ready to start development on your project! The CI/CD pipeline will be triggered when you open a pull request, merge to main, or when you create a new release. To finalize the set-up for publishing to PyPi or Artifactory, see here . For activating the automatic documentation with MkDocs, see here . To enable the code coverage reports, see here . Acknowledgements \u00b6 This project is partially based on Audrey Feldroy's great cookiecutter-pypackage .","title":"Home"},{"location":"#quickstart","text":"On your local machine, navigate to the directory in which you want to create a project directory, and run the following two commands: pip install cookiecutter-poetry ccp Alternatively, install cookiecutter and directly pass the URL to this Github repository to the cookiecutter command: pip install cookiecutter cookiecutter https://github.com/fpgmaas/cookiecutter-poetry.git Create a repository on GitHub, and then run the following commands, replacing <project-name> , with the name that you gave the Github repository and <github_author_handle> with your Github username. cd <project_name> git init -b main git add . git commit -m \"Init commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main Finally, install the environment and the pre-commit hooks with make install You are now ready to start development on your project! The CI/CD pipeline will be triggered when you open a pull request, merge to main, or when you create a new release. To finalize the set-up for publishing to PyPi or Artifactory, see here . For activating the automatic documentation with MkDocs, see here . To enable the code coverage reports, see here .","title":"Quickstart"},{"location":"#acknowledgements","text":"This project is partially based on Audrey Feldroy's great cookiecutter-pypackage .","title":"Acknowledgements"},{"location":"prompt_arguments/","text":"Prompt arguments \u00b6 When running the command ccp a prompt will start which enables you to configure your repository. The prompt values and their explanation are as follows: author Your full name. email Your email address. author_github_handle Your github handle, i.e. <handle> in https://github.com/<handle> project_name Your project name. Should be equal to the name of your repository and it should only contain alphanumeric characters and - 's. project_slug The project slug, will default to the project_name with all - 's replaced with _ . This will be how you import your code later, e.g. from <project_slug> import foo project_description A short description of your project. include_github_actions \"y\" or \"n\" . Adds a .github directory with various actions and workflows to setup the environment and run code formatting checks and unittests. publish_to \"pypi\" , \"artifactory\" , or \"none\" . Adds functionality to the Makefile and Github workflows to make publishing your code as simple as creating a new release release on Github. For more info, see Publishing to Pypi or Artifactory . deptry \"y\" or \"n\" . Adds deptry to the development dependencies of the project, and adds it to the make check command. deptry is a command line tool to check for issues with dependencies in a Python project, such as obsolete or missing dependencies. mkdocs \"y\" or \"n\" . Adds MkDocs documentation to your project. This includes automatically parsing your docstrings and adding them to the documentation. Documentation will be deployed to the gh-pages branch. codecov \"y\" or \"n\" . Adds code coverage checks with codecov . dockerfile \"y\" or \"n\" . Adds a simple Dockerfile . devcontainer \"y\" or \"n\" . Adds a devcontainer specification to the project along with pre-installed pre-commit hooks and VSCode python extension configuration. open_source_license Choose a license . Options: [\"1. MIT License\", \"2. BSD license\", \"3. ISC license\", \"4. Apache Software License 2.0\", \"5. GNU General Public License v3\", \"6. Not open source\"]","title":"Prompt Arguments"},{"location":"prompt_arguments/#prompt-arguments","text":"When running the command ccp a prompt will start which enables you to configure your repository. The prompt values and their explanation are as follows: author Your full name. email Your email address. author_github_handle Your github handle, i.e. <handle> in https://github.com/<handle> project_name Your project name. Should be equal to the name of your repository and it should only contain alphanumeric characters and - 's. project_slug The project slug, will default to the project_name with all - 's replaced with _ . This will be how you import your code later, e.g. from <project_slug> import foo project_description A short description of your project. include_github_actions \"y\" or \"n\" . Adds a .github directory with various actions and workflows to setup the environment and run code formatting checks and unittests. publish_to \"pypi\" , \"artifactory\" , or \"none\" . Adds functionality to the Makefile and Github workflows to make publishing your code as simple as creating a new release release on Github. For more info, see Publishing to Pypi or Artifactory . deptry \"y\" or \"n\" . Adds deptry to the development dependencies of the project, and adds it to the make check command. deptry is a command line tool to check for issues with dependencies in a Python project, such as obsolete or missing dependencies. mkdocs \"y\" or \"n\" . Adds MkDocs documentation to your project. This includes automatically parsing your docstrings and adding them to the documentation. Documentation will be deployed to the gh-pages branch. codecov \"y\" or \"n\" . Adds code coverage checks with codecov . dockerfile \"y\" or \"n\" . Adds a simple Dockerfile . devcontainer \"y\" or \"n\" . Adds a devcontainer specification to the project along with pre-installed pre-commit hooks and VSCode python extension configuration. open_source_license Choose a license . Options: [\"1. MIT License\", \"2. BSD license\", \"3. ISC license\", \"4. Apache Software License 2.0\", \"5. GNU General Public License v3\", \"6. Not open source\"]","title":"Prompt arguments"},{"location":"tutorial/","text":"Tutorial \u00b6 This page contains a complete tutorial on how to create your project. Step 1: Install poetry \u00b6 To start, we will need to install poetry . The instructions to install poetry can be found here . After installing, it is recommended to run poetry config virtualenvs.in-project true which will by default create new virtual environments in ./.venv whenever you create them with poetry init . Step 2: Install pyenv (Optional) \u00b6 I would recommend to use pyenv for managing your different Python versions. However, if you prefer another method of managing your Python versions, feel free to skip this step and continue to step 3 . The instructions to install pyenv can be found here . The instructions to install poetry can be found here . Install a version of Python with pyenv. To see a list of available versions, run: pyenv install --list Select a version and install it with pyenv install -v 3.9.7 Replacing 3.9.7 with a version of your choosing. Step 3: Generate your project \u00b6 First, navigate to the directory in which you want the project to be created. Then, we need to install cookiecutter-poetry with the following command: pip install cookiecutter-poetry Within the directory in which you want to create your project, run: ccp For an explanation of the prompt arguments, see Prompt Arguments . An alternative to the steps above would be to install cookiecutter and directly pass the URL to Github repository to the cookiecutter command: pip install cookiecutter-poetry cookiecutter https://github.com/fpgmaas/cookiecutter-poetry.git Step 4: Set up your Github repository \u00b6 Create an empty new repository on Github. Give it a name that only contains alphanumeric characters and optionally - . DO NOT check any boxes under the option Initialize this repository with . Step 5: Upload your project to Github \u00b6 Run the following commands, replacing <project-name> with the name that you also gave the Github repository and <github_author_handle> with your Github username. cd <project_name> git init -b main git add . git commit -m \"Init commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main Step 6: Activate your environment \u00b6 If you are using pyenv , you might want to set the local python version to be used: pyenv local x.y.z Install and activate the poetry environment by running: make install poetry shell Step 7: Sign up to codecov.io \u00b6 If you enabled code coverage with codecov for your project, you should sign up with your GitHub account at codecov.io Step 8: Configure your repository secrets \u00b6 If you want to deploy your project to Pypi or Artifactory using the Github Actions, you will have to set some repository secrets. For instructions on how to do that, see here for PyPi, or here for Artifactory. Step 9: Create a new release \u00b6 To trigger a new release, navigate to your repository on GitHub, click Releases on the right, and then select Draft a new release . If you fail to find the button, you could also directly visit https://github.com/<username>/<repository-name>/releases/new . Give your release a title, and add a new tag in the form *.*.* where the * 's are alphanumeric. To finish, press Publish release . Step 10: Enable your documentation \u00b6 In your repository, navigate to Settings > Code and Automation > Pages . If you succesfully created a new release, you should see a notification saying Your site is ready to be published at https://<author_github_handle>.github.io/<project_name>/ . To finalize deploying your documentation, under Source , select the branch gh-pages . Step 11: You're all set! \u00b6 That's it! I hope this repository saved you a lot of manual configuration. If you have any improvement suggestions, feel free to raise an issue or open a PR on Github!","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"This page contains a complete tutorial on how to create your project.","title":"Tutorial"},{"location":"tutorial/#step-1-install-poetry","text":"To start, we will need to install poetry . The instructions to install poetry can be found here . After installing, it is recommended to run poetry config virtualenvs.in-project true which will by default create new virtual environments in ./.venv whenever you create them with poetry init .","title":"Step 1: Install poetry"},{"location":"tutorial/#step-2-install-pyenv-optional","text":"I would recommend to use pyenv for managing your different Python versions. However, if you prefer another method of managing your Python versions, feel free to skip this step and continue to step 3 . The instructions to install pyenv can be found here . The instructions to install poetry can be found here . Install a version of Python with pyenv. To see a list of available versions, run: pyenv install --list Select a version and install it with pyenv install -v 3.9.7 Replacing 3.9.7 with a version of your choosing.","title":"Step 2: Install pyenv (Optional)"},{"location":"tutorial/#step-3-generate-your-project","text":"First, navigate to the directory in which you want the project to be created. Then, we need to install cookiecutter-poetry with the following command: pip install cookiecutter-poetry Within the directory in which you want to create your project, run: ccp For an explanation of the prompt arguments, see Prompt Arguments . An alternative to the steps above would be to install cookiecutter and directly pass the URL to Github repository to the cookiecutter command: pip install cookiecutter-poetry cookiecutter https://github.com/fpgmaas/cookiecutter-poetry.git","title":"Step 3: Generate your project"},{"location":"tutorial/#step-4-set-up-your-github-repository","text":"Create an empty new repository on Github. Give it a name that only contains alphanumeric characters and optionally - . DO NOT check any boxes under the option Initialize this repository with .","title":"Step 4: Set up your Github repository"},{"location":"tutorial/#step-5-upload-your-project-to-github","text":"Run the following commands, replacing <project-name> with the name that you also gave the Github repository and <github_author_handle> with your Github username. cd <project_name> git init -b main git add . git commit -m \"Init commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main","title":"Step 5: Upload your project to Github"},{"location":"tutorial/#step-6-activate-your-environment","text":"If you are using pyenv , you might want to set the local python version to be used: pyenv local x.y.z Install and activate the poetry environment by running: make install poetry shell","title":"Step 6: Activate your environment"},{"location":"tutorial/#step-7-sign-up-to-codecovio","text":"If you enabled code coverage with codecov for your project, you should sign up with your GitHub account at codecov.io","title":"Step 7: Sign up to codecov.io"},{"location":"tutorial/#step-8-configure-your-repository-secrets","text":"If you want to deploy your project to Pypi or Artifactory using the Github Actions, you will have to set some repository secrets. For instructions on how to do that, see here for PyPi, or here for Artifactory.","title":"Step 8: Configure your repository secrets"},{"location":"tutorial/#step-9-create-a-new-release","text":"To trigger a new release, navigate to your repository on GitHub, click Releases on the right, and then select Draft a new release . If you fail to find the button, you could also directly visit https://github.com/<username>/<repository-name>/releases/new . Give your release a title, and add a new tag in the form *.*.* where the * 's are alphanumeric. To finish, press Publish release .","title":"Step 9: Create a new release"},{"location":"tutorial/#step-10-enable-your-documentation","text":"In your repository, navigate to Settings > Code and Automation > Pages . If you succesfully created a new release, you should see a notification saying Your site is ready to be published at https://<author_github_handle>.github.io/<project_name>/ . To finalize deploying your documentation, under Source , select the branch gh-pages .","title":"Step 10: Enable your documentation"},{"location":"tutorial/#step-11-youre-all-set","text":"That's it! I hope this repository saved you a lot of manual configuration. If you have any improvement suggestions, feel free to raise an issue or open a PR on Github!","title":"Step 11: You're all set!"},{"location":"features/cicd/","text":"CI/CD with Github actions \u00b6 when include_github_actions is set to \"y\" , a .github directory is added with the following structure: .github \u251c\u2500\u2500 workflows \u251c\u2500\u2500\u2500 run-checks \u2502 \u2514\u2500\u2500 action.yml \u251c\u2500\u2500\u2500 setup-poetry-env \u2502 \u2514\u2500\u2500 action.yml \u251c\u2500\u2500 on-merge-to-main.yml \u251c\u2500\u2500 on-pull-request.yml \u2514\u2500\u2500 on-release-main.yml on-merge-to-main.yml and on-pull-request.yml are identical except for their trigger conditions; the first is run whenever a new commit is made to main (which should only happen through merge requests, hence the name), and the latter is run whenever a pull request is opened or updated. They call the action.yml files to set-up the environment, run the tests, and check the code formatting. on-release-main.yml does all of the former whenever a new release is made on the main branch. In addition, on-release-main.yml also publishes the project to Pypi or Artifactory if publish_to is set to \"pypi\" or \"artifactory\" , and it builds and deploys the documentation if mkdocs is set to \"y\" . To learn more about these features, see Publishing to PyPi or Artifactory and Documentation with MkDocs Additionally, all workflows check for compatibility with multiple Python versions if tox is set to \"y\" . How to trigger a release? \u00b6 To trigger a new release, navigate to your repository on GitHub, click Releases on the right, and then select Draft a new release . If you fail to find the button, you could also directly visit https://github.com/<username>/<repository-name>/releases/new . Give your release a title, and add a new tag in the form *.*.* where the * 's are alphanumeric. To finish, press Publish release .","title":"CI/CD with Github Actions"},{"location":"features/cicd/#cicd-with-github-actions","text":"when include_github_actions is set to \"y\" , a .github directory is added with the following structure: .github \u251c\u2500\u2500 workflows \u251c\u2500\u2500\u2500 run-checks \u2502 \u2514\u2500\u2500 action.yml \u251c\u2500\u2500\u2500 setup-poetry-env \u2502 \u2514\u2500\u2500 action.yml \u251c\u2500\u2500 on-merge-to-main.yml \u251c\u2500\u2500 on-pull-request.yml \u2514\u2500\u2500 on-release-main.yml on-merge-to-main.yml and on-pull-request.yml are identical except for their trigger conditions; the first is run whenever a new commit is made to main (which should only happen through merge requests, hence the name), and the latter is run whenever a pull request is opened or updated. They call the action.yml files to set-up the environment, run the tests, and check the code formatting. on-release-main.yml does all of the former whenever a new release is made on the main branch. In addition, on-release-main.yml also publishes the project to Pypi or Artifactory if publish_to is set to \"pypi\" or \"artifactory\" , and it builds and deploys the documentation if mkdocs is set to \"y\" . To learn more about these features, see Publishing to PyPi or Artifactory and Documentation with MkDocs Additionally, all workflows check for compatibility with multiple Python versions if tox is set to \"y\" .","title":"CI/CD with Github actions"},{"location":"features/cicd/#how-to-trigger-a-release","text":"To trigger a new release, navigate to your repository on GitHub, click Releases on the right, and then select Draft a new release . If you fail to find the button, you could also directly visit https://github.com/<username>/<repository-name>/releases/new . Give your release a title, and add a new tag in the form *.*.* where the * 's are alphanumeric. To finish, press Publish release .","title":"How to trigger a release?"},{"location":"features/codecov/","text":"Test coverage with codecov \u00b6 If codecov is set to \"y\" , pytest-cov is added as a development dependency, and make test will run the tests and output a coverage report as coverage.xml . If include_github_actions is set to \"y\" , coverage tests with codecov are added to the CI/CD pipeline. To enable this, sign up at codecov.io with your GitHub account. Additionally, a codecov.yaml file is created, with the following defaults: # Badge color changes from red to green between 70% and 100% # PR pipeline fails if codecov falls with 1% coverage: range: 70..100 round: down precision: 1 status: project: default: target: auto threshold: 1% # Ignoring Paths # -------------- # which folders/files to ignore ignore: - \"foo/bar.py\"","title":"Test coverage with codecov"},{"location":"features/codecov/#test-coverage-with-codecov","text":"If codecov is set to \"y\" , pytest-cov is added as a development dependency, and make test will run the tests and output a coverage report as coverage.xml . If include_github_actions is set to \"y\" , coverage tests with codecov are added to the CI/CD pipeline. To enable this, sign up at codecov.io with your GitHub account. Additionally, a codecov.yaml file is created, with the following defaults: # Badge color changes from red to green between 70% and 100% # PR pipeline fails if codecov falls with 1% coverage: range: 70..100 round: down precision: 1 status: project: default: target: auto threshold: 1% # Ignoring Paths # -------------- # which folders/files to ignore ignore: - \"foo/bar.py\"","title":"Test coverage with codecov"},{"location":"features/devcontainer/","text":"Reproducible development environments with VSCode devcontainers \u00b6 If devcontainer is set to \"y\" project uses the VSCode devcontainer specification to create a reproducible development environment. The devcontainer is defined in the .devcontainer directory and pre-installs all dependencies from poetry required to develop, test and build the project. The devcontainer also installs the pre-commit hooks and configures the VSCode python extension to use the appropriate python interpretor and pytest paths.","title":"Devcontainer with VSCode"},{"location":"features/devcontainer/#reproducible-development-environments-with-vscode-devcontainers","text":"If devcontainer is set to \"y\" project uses the VSCode devcontainer specification to create a reproducible development environment. The devcontainer is defined in the .devcontainer directory and pre-installs all dependencies from poetry required to develop, test and build the project. The devcontainer also installs the pre-commit hooks and configures the VSCode python extension to use the appropriate python interpretor and pytest paths.","title":"Reproducible development environments with VSCode devcontainers"},{"location":"features/docker/","text":"Containerization with Docker \u00b6 If dockerfile is set to \"y\" , a simple Dockerfile is added to the repository. The Dockerfile installs poetry, sets up the environment and runs foo.py when run. The docker image can be built with docker build . -t my-docker-image It can then be run in the background with docker run -d my-docker-image Or, run it interactive mode with docker run --rm -it --entrypoint bash my-docker-image","title":"Containerization with Docker"},{"location":"features/docker/#containerization-with-docker","text":"If dockerfile is set to \"y\" , a simple Dockerfile is added to the repository. The Dockerfile installs poetry, sets up the environment and runs foo.py when run. The docker image can be built with docker build . -t my-docker-image It can then be run in the background with docker run -d my-docker-image Or, run it interactive mode with docker run --rm -it --entrypoint bash my-docker-image","title":"Containerization with Docker"},{"location":"features/linting/","text":"Linting and code quality \u00b6 Code can be linted and quality-checked with the command make check Note that this requires the pre-commit hooks to be installed. This command will run the following tools: ruff \u00b6 ruff is used to lint and format the code, and it is configured through pyproject.toml : [tool.ruff] target-version = \"py37\" line-length = 120 fix = false select = [ # flake8-2020 \"YTT\", # flake8-bandit \"S\", # flake8-bugbear \"B\", # flake8-builtins \"A\", # flake8-comprehensions \"C4\", # flake8-debugger \"T10\", # flake8-print \"T20\", # flake8-simplify \"SIM\", # isort \"I\", # mccabe \"C90\", # pycodestyle \"E\", \"W\", # pyflakes \"F\", # pygrep-hooks \"PGH\", # pyupgrade \"UP\", # ruff \"RUF\", # tryceratops \"TRY\", ] ignore = [ # LineTooLong \"E501\", # DoNotAssignLambda \"E731\", ] [tool.ruff.per-file-ignores] \"tests/*\" = [\"S101\"] mypy \u00b6 mypy is used for static type checking, and it's configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ] deptry \u00b6 deptry is used to check the code for dependency issues, and it's configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ] Prettier \u00b6 Prettier is used to format the markdown documentation, along with any json and yaml files. Its options can be configured in the included .editorconfig file or in greater detail by adding a .prettierrc file ( See Docs ). [*] max_line_length = 120 [*.json] indent_style = space indent_size = 4 Github Actions \u00b6 If include_github_actions is set to \"y\" , code formatting is checked for every merge request, every merge to main, and every release.","title":"Linting & code quality"},{"location":"features/linting/#linting-and-code-quality","text":"Code can be linted and quality-checked with the command make check Note that this requires the pre-commit hooks to be installed. This command will run the following tools:","title":"Linting and code quality"},{"location":"features/linting/#ruff","text":"ruff is used to lint and format the code, and it is configured through pyproject.toml : [tool.ruff] target-version = \"py37\" line-length = 120 fix = false select = [ # flake8-2020 \"YTT\", # flake8-bandit \"S\", # flake8-bugbear \"B\", # flake8-builtins \"A\", # flake8-comprehensions \"C4\", # flake8-debugger \"T10\", # flake8-print \"T20\", # flake8-simplify \"SIM\", # isort \"I\", # mccabe \"C90\", # pycodestyle \"E\", \"W\", # pyflakes \"F\", # pygrep-hooks \"PGH\", # pyupgrade \"UP\", # ruff \"RUF\", # tryceratops \"TRY\", ] ignore = [ # LineTooLong \"E501\", # DoNotAssignLambda \"E731\", ] [tool.ruff.per-file-ignores] \"tests/*\" = [\"S101\"]","title":"ruff"},{"location":"features/linting/#mypy","text":"mypy is used for static type checking, and it's configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ]","title":"mypy"},{"location":"features/linting/#deptry","text":"deptry is used to check the code for dependency issues, and it's configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ]","title":"deptry"},{"location":"features/linting/#prettier","text":"Prettier is used to format the markdown documentation, along with any json and yaml files. Its options can be configured in the included .editorconfig file or in greater detail by adding a .prettierrc file ( See Docs ). [*] max_line_length = 120 [*.json] indent_style = space indent_size = 4","title":"Prettier"},{"location":"features/linting/#github-actions","text":"If include_github_actions is set to \"y\" , code formatting is checked for every merge request, every merge to main, and every release.","title":"Github Actions"},{"location":"features/makefile/","text":"Makefile \u00b6 The generated repository will have a Makefile available. A list of all available commands that are available can be obtained by running make help in the terminal. Initially, if all features are selected, the following commands are available: install Install the poetry environment and install the pre-commit hooks check Lint and check code by running ruff, mypy and deptry. test Test the code with pytest build Build wheel file using poetry clean-build clean build artifacts publish publish a release to pypi. build-and-publish Build and publish. docs-test Test if documentation can be built without warnings or errors docs Build and serve the documentation","title":"Makefile"},{"location":"features/makefile/#makefile","text":"The generated repository will have a Makefile available. A list of all available commands that are available can be obtained by running make help in the terminal. Initially, if all features are selected, the following commands are available: install Install the poetry environment and install the pre-commit hooks check Lint and check code by running ruff, mypy and deptry. test Test the code with pytest build Build wheel file using poetry clean-build clean build artifacts publish publish a release to pypi. build-and-publish Build and publish. docs-test Test if documentation can be built without warnings or errors docs Build and serve the documentation","title":"Makefile"},{"location":"features/mkdocs/","text":"Documentation with MkDocs \u00b6 If mkdocs is set to \"y\" , documentation of your project is automatically added using MkDocs . Next to that, if \"include_github_actions\" is set to \"y\" , the documentation is automatically deployed to your gh-pages branch, and made available at https://<github_handle>.github.io/<project_name>/ . To view the documentation locally, simply run make docs This command will generate and build your documentation, and start the server locally so you can access it at http://localhost:8000 . Enabling the documentation on GitHub \u00b6 To enable your documentation on GitHub, first create a new release . Then, in your repository, navigate to Settings > Code and Automation > Pages . If you succesfully created a new release, you should see a notification saying Your site is ready to be published at https://<author_github_handle>.github.io/<project_name>/ . To finalize deploying your documentation, under Source , select the branch gh-pages . Your documentation should then be live within a few minutes. Documenting docstrings \u00b6 The generated project also converts all your docstrings into legible documentation. By default, the project is configured to work with google style docstrings. An example of a Google style docstring: def function_with_pep484_type_annotations(param1: int, param2: str) -> bool: \"\"\"Example function with PEP 484 type annotations. Args: param1: The first parameter. param2: The second parameter. Returns: The return value. True for success, False otherwise. For more examples, see here .","title":"Documentation with MkDocs"},{"location":"features/mkdocs/#documentation-with-mkdocs","text":"If mkdocs is set to \"y\" , documentation of your project is automatically added using MkDocs . Next to that, if \"include_github_actions\" is set to \"y\" , the documentation is automatically deployed to your gh-pages branch, and made available at https://<github_handle>.github.io/<project_name>/ . To view the documentation locally, simply run make docs This command will generate and build your documentation, and start the server locally so you can access it at http://localhost:8000 .","title":"Documentation with MkDocs"},{"location":"features/mkdocs/#enabling-the-documentation-on-github","text":"To enable your documentation on GitHub, first create a new release . Then, in your repository, navigate to Settings > Code and Automation > Pages . If you succesfully created a new release, you should see a notification saying Your site is ready to be published at https://<author_github_handle>.github.io/<project_name>/ . To finalize deploying your documentation, under Source , select the branch gh-pages . Your documentation should then be live within a few minutes.","title":"Enabling the documentation on GitHub"},{"location":"features/mkdocs/#documenting-docstrings","text":"The generated project also converts all your docstrings into legible documentation. By default, the project is configured to work with google style docstrings. An example of a Google style docstring: def function_with_pep484_type_annotations(param1: int, param2: str) -> bool: \"\"\"Example function with PEP 484 type annotations. Args: param1: The first parameter. param2: The second parameter. Returns: The return value. True for success, False otherwise. For more examples, see here .","title":"Documenting docstrings"},{"location":"features/poetry/","text":"Dependency management with Poetry \u00b6 The generated repository will uses Poetry for its dependency management. When you have created your repository using this cookiecutter template, a Poetry environment is pre-configured in pyproject.toml and Poetry.toml . All you need to do is add your project-specific dependencies with poetry add <package> and then install the environment with make install By default, the environment is created in a .venv folder, so you can easily start an interactive shell within the environment with poetry shell .","title":"Dependency management with Poetry"},{"location":"features/poetry/#dependency-management-with-poetry","text":"The generated repository will uses Poetry for its dependency management. When you have created your repository using this cookiecutter template, a Poetry environment is pre-configured in pyproject.toml and Poetry.toml . All you need to do is add your project-specific dependencies with poetry add <package> and then install the environment with make install By default, the environment is created in a .venv folder, so you can easily start an interactive shell within the environment with poetry shell .","title":"Dependency management with Poetry"},{"location":"features/publishing/","text":"Publishing to Pypi or Artifactory \u00b6 Releasing from Github \u00b6 When publish_to is set to \"pypi\" or \"artifactory\" , the on-release-main.yml workflow publishes the code to Pypi or Artifactory respectively whenever a new release is made. Before you can succesfully publish your project from the release workflow, you need to add some secrets to your github repository so they can be used as environment variables. Set-up for Pypi \u00b6 In order to publish to Pypi, the secret PYPI_TOKEN should be set in your repository. In your Github repository, navigate to Settings > Secrets > Actions and press New repository secret . As the name of the secret, set PYPI_TOKEN . Then, in a new tab go to your Pypi Account settings and select Add API token . Copy and paste the token in the Value field for the Github secret in your first tab, and you're all set! Set-up for Artifactory \u00b6 In order to release to Artifactory , visit your Artifactory instance and open Quick setup . You should see something like this: You should add these as secrets to your repository with the names ARTIFACTORY_URL , ARTIFACTORY_USERNAME and ARTIFACTORY_PASSWORD respectively. To do so, in your Github repository, navigate to Settings > Secrets > Actions and create a secret by pressing New repository secret to add the secrets one by one. Publishing from your local machine \u00b6 It is also possible to release locally, although it is not recommended. To do so, set the repository secrets listed in the sections above as environment variables on your local machine instead, and run make build-and-publish","title":"Publishing to PyPi or Artifactory"},{"location":"features/publishing/#publishing-to-pypi-or-artifactory","text":"","title":"Publishing to Pypi or Artifactory"},{"location":"features/publishing/#releasing-from-github","text":"When publish_to is set to \"pypi\" or \"artifactory\" , the on-release-main.yml workflow publishes the code to Pypi or Artifactory respectively whenever a new release is made. Before you can succesfully publish your project from the release workflow, you need to add some secrets to your github repository so they can be used as environment variables.","title":"Releasing from Github"},{"location":"features/publishing/#set-up-for-pypi","text":"In order to publish to Pypi, the secret PYPI_TOKEN should be set in your repository. In your Github repository, navigate to Settings > Secrets > Actions and press New repository secret . As the name of the secret, set PYPI_TOKEN . Then, in a new tab go to your Pypi Account settings and select Add API token . Copy and paste the token in the Value field for the Github secret in your first tab, and you're all set!","title":"Set-up for Pypi"},{"location":"features/publishing/#set-up-for-artifactory","text":"In order to release to Artifactory , visit your Artifactory instance and open Quick setup . You should see something like this: You should add these as secrets to your repository with the names ARTIFACTORY_URL , ARTIFACTORY_USERNAME and ARTIFACTORY_PASSWORD respectively. To do so, in your Github repository, navigate to Settings > Secrets > Actions and create a secret by pressing New repository secret to add the secrets one by one.","title":"Set-up for Artifactory"},{"location":"features/publishing/#publishing-from-your-local-machine","text":"It is also possible to release locally, although it is not recommended. To do so, set the repository secrets listed in the sections above as environment variables on your local machine instead, and run make build-and-publish","title":"Publishing from your local machine"},{"location":"features/pytest/","text":"Unittesting with Pytest \u00b6 pytest is automatically added to the environment. There will be a template unittest in the tests directory upon creation of the project, which can be run with make test If include_github_actions is set to \"y\" , the tests are automatically run for every merge request, every merge to main, and every release.","title":"Testing with Pytest"},{"location":"features/pytest/#unittesting-with-pytest","text":"pytest is automatically added to the environment. There will be a template unittest in the tests directory upon creation of the project, which can be run with make test If include_github_actions is set to \"y\" , the tests are automatically run for every merge request, every merge to main, and every release.","title":"Unittesting with Pytest"},{"location":"features/tox/","text":"Compatibility testing with Tox \u00b6 If tox is set to \"y\" project uses Tox to test compatibility with multiple Python versions. By default, the project is tested with Python 3.8 , 3.9 , and 3.10 . Testing is done automatically in the CI/CD pipeline on every pull request, merge to main, and on each release. If you want to add more Python versions you can simply add them to tox.ini and to the separate workflows in .github .","title":"Compatibility testing with Tox"},{"location":"features/tox/#compatibility-testing-with-tox","text":"If tox is set to \"y\" project uses Tox to test compatibility with multiple Python versions. By default, the project is tested with Python 3.8 , 3.9 , and 3.10 . Testing is done automatically in the CI/CD pipeline on every pull request, merge to main, and on each release. If you want to add more Python versions you can simply add them to tox.ini and to the separate workflows in .github .","title":"Compatibility testing with Tox"}]}